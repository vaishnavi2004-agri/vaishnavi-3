# -*- coding: utf-8 -*-
"""vaishu ( level 2)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19YFOZ1TZ1uV7rmmglkheMYOokPoVdeZt
"""

1. Install Required Libraries

import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow.keras.layers import Dense, Flatten, Reshape
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam

2. Define the Generator Model

def build_generator(latent_dim):
    model = Sequential()
    model.add(Dense(128, activation='relu', input_dim=latent_dim))
    model.add(Dense(784, activation='sigmoid'))
    model.add(Reshape((28, 28, 1)))
    return model

3. Define the Discriminator Model

def build_discriminator():
    model = Sequential()
    model.add(Flatten(input_shape=(28, 28, 1)))
    model.add(Dense(128, activation='relu'))
    model.add(Dense(1, activation='sigmoid'))
    return model

4. Define the GAN Model

def build_gan(generator, discriminator):
    discriminator.trainable = false
    model = Sequential()
    model.add(generator)
    model.add(discriminator)
    return model

5.Compile the Models
discriminator = build_discriminator()
discriminator.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])


latent_dim = 100
generator = build_generator(latent_dim)
gan = build_gan(generator, discriminator)
gan.compile(loss='binary_crossentropy', optimizer=Adam())

6. Prepare the Dataset (MNIST)
The MNIST dataset is available in tensorflow.keras.datasets. We normalize the images to have values in the range [-1, 1] (because the generator produces values in this range).

Load the MNIST dataset
(x_train, _), (_, _) = tf.keras.datasets.mnist.load_data()
x_train = (x_train / 127.5) - 1.0
x_train = np.expand_dims(x_train, axis=-1)
8. Train the GAN
We now define the training loop. The loop will alternate between training the discriminator on real and fake images and training the generator to fool the discriminator.


Number of training epochs
epochs = 10000
batch_size = 64
half_batch = batch_size // 2

Training loop
for epoch in range(epochs):
    Train discriminator
    idx = np.random.randint(0, x_train.shape[0], half_batch)
    real_images = x_train[idx]
    fake_images = generator.predict(np.random.normal(0, 1, (half_batch, latent_dim)))

    Labels for real and fake images
    real_labels = np.ones((half_batch, 1))
    fake_labels = np.zeros((half_batch, 1))

    Train on real and fake images
    d_loss_real = discriminator.train_on_batch(real_images, real_labels)
    d_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)
    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

    Train generator (to fool the discriminator)
    noise = np.random.normal(0, 1, (batch_size, latent_dim))
    valid_labels = np.ones((batch_size, 1))
    g_loss = gan.train_on_batch(noise, valid_labels)

    Print the progress
    if epoch % 1000 == 0:
        print(f"{epoch} [D loss: {d_loss[0]} | D accuracy: {100*d_loss[1]}] [G loss: {g_loss}]")

    Generate and save images at intervals
    if epoch % 1000 == 0:
        noise = np.random.normal(0, 1, (25, latent_dim))
        generated_images = generator.predict(noise)
        generated_images = (generated_images + 1) / 2.0

        fig, axs = plt.subplots(5, 5, figsize=(5, 5))
        cnt = 0
        for i in range(5):
            for j in range(5):
                axs[i, j].imshow(generated_images[cnt, :, :, 0], cmap='gray')
                axs[i, j].axis('off')
                cnt += 1
        plt.show()


Generate images using the trained generator
noise = np.random.normal(0, 1, (5, latent_dim))
generated_images = generator.predict(noise)
generated_images = (generated_images + 1) / 2.0

Display the generated images
fig, axs = plt.subplots(1, 5, figsize=(10, 2))
for i in range(5):
    axs[i].imshow(generated_images[i, :, :, 0], cmap='gray')
    axs[i].axis('off')
plt.show()

import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.model_selection import train_test_split
from tensorflow.keras.datasets import mnist
from tensorflow.keras.utils import to_categorical
2. Model Building Libraries
These libraries allow you to create deep learning models, neural networks, or traditional machine learning models.

Keras/TensorFlow: For building and training neural networks (and deep learning models).
scikit-learn: For building traditional machine learning models like SVMs, Decision Trees, etc.


from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Reshape, Conv2D, MaxPooling2D
from tensorflow.keras.optimizers import Adam, SGD
from tensorflow.keras import backend as K
3. Model Evaluation Libraries
Evaluation of the model's performance is crucial for assessing how well your model is performing on unseen data. These libraries help with:

Metrics (Accuracy, Precision, Recall, etc.)
Plotting (confusion matrix, accuracy, loss curves)


from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns
4. Model Saving and Loading Libraries
For saving and loading models after training to avoid retraining from scratch.

TensorFlow Keras has built-in functions to save/load models in various formats (e.g., .h5, TensorFlow .pb format).
python
Copy code
from tensorflow.keras.models import load_model
5. Other Useful Libraries
Additional libraries for handling visualizations, handling images, or random data generation.

import os
import random
from PIL import Image
Example Code to Import Libraries and Process Data
Hereâ€™s a basic example that imports libraries, loads a dataset (MNIST), preprocesses it, and splits it into training and testing sets:

Data processing
import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.model_selection import train_test_split
from tensorflow.keras.datasets import mnist
from tensorflow.keras.utils import to_categorical

Model building
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Reshape
from tensorflow.keras.optimizers import Adam

Model evaluation
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns

Data loading and preprocessing
(x_train, y_train), (x_test, y_test) = mnist.load_data()

Normalize the images to [0, 1]
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

Reshape data to include channels (for CNNs)
x_train = np.expand_dims(x_train, axis=-1)
x_test = np.expand_dims(x_test, axis=-1)

One-hot encode labels
y_train = to_categorical(y_train, 10)
y_test = to_categorical(y_test, 10)


x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)

model = Sequential([
    Flatten(input_shape=(28, 28, 1))
    Dense(128, activation='relu'),
    Dense(10, activation='softmax')
])

Compile the model
model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])

Train the model
history = model.fit(x_train, y_train, epochs=10, batch_size=64, validation_data=(x_val, y_val))

Evaluate the model
y_pred = model.predict(x_test)
y_pred_classes = np.argmax(y_pred, axis=1)

Model evaluation
accuracy = accuracy_score(np.argmax(y_test, axis=1), y_pred_classes)
print(f"Accuracy: {accuracy * 100:.2f}%")

Confusion Matrix
cm = confusion_matrix(np.argmax(y_test, axis=1), y_pred_classes)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.arange(10), yticklabels=np.arange(10))
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

Classification report
print(classification_report(np.argmax(y_test, axis=1), y_pred_classes))

Step-2:

   Load Data :


df = pd.read_csv('path_to_your_file.csv', sep=';


df_json = pd.read_json('path_to_your_file.jso
from pandas import json_normalize


json_data = {
    "name": "John",
    "location": {
        "city": "New York",
        "state": "NY"
    },
    "contacts": [
        {"type": "email", "value": "john@example.com"},
        {"type": "phone", "value": "123-456-7890"}
    ]
}


df_normalized = json_normalize(json_data, record_path='contacts', meta=['name', ['location', 'city'], ['location', 'state']])

df_normalized.head()
3. Text Files
Text files can be loaded in various ways depending on the structure of the file. If each line in the text file corresponds to a row of data, you can load it with Pandas using the pd.read_csv() function with the correct delimiter (like spaces or tabs). If the file has a more complex structure, you might need to process the text manually.

Example: Load a text file (line-by-line)

df_text = pd.read_csv('path_to_your_file.txt', delimiter=' ')


df_text.head()
Example: Read raw text data from a text file
If the text file isn't structured like CSV, you can read it line-by-line:


with open('path_to_your_file.txt', 'r') as file:
    text_data = file.readlines

print(text_data[:5])
4. Loading Data from Google Drive (Google Colab)
In Google Colab, you might want to load data from your Google Drive. Here's how to do that:

First, mount your Google Drive:


from google.colab import drive
drive.mount('/content/drive')


file_path = '/content/drive/My Drive/your_folder/your_file.csv'
df = pd.read_csv(file_path)

df.head()
Example: Using a CSV dataset
Let's assume you have a simple CSV file with the following
import pandas as pd


df = pd.read_csv('people.csv')

df.head()
Output:
markdown

Step-3: Data Preprocessing:

 import pandas as pd
import string
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer

Download stopwords from NLTK if not already downloaded
import nltk
nltk.download('punkt')
nltk.download('stopwords')

Example text dataset
data = {'text': ['I love programming in Python', 'Python is great for data science', 'I enjoy machine learning', 'Deep learning is fascinating'],
        'label': [1, 1, 1, 0]}

df = pd.DataFrame(data)

 Preprocessing function for text
def preprocess_text(text):
    Convert to lowercase
    text = text.lower()

    Remove punctuation and digits
    text = ''.join([char for char in text if char not in string.punctuation and not char.isdigit()])

    Tokenize text
    tokens = word_tokenize(text)


    stop_words = set(stopwords.words('english'))
    tokens = [word for word in tokens if word not in stop_words]

    return ' '.join(tokens)


df['cleaned_text'] = df['text'].apply(preprocess_text)


print(df[['text', 'cleaned_text'

Vectorizing Text (Tokenization and TF-IDF)
Next, we convert the cleaned text into a numerical form using TF-IDF Vectorizer:

TF-IDF Vectorization
vectorizer = TfidfVectorizer(max_features=100)
X = vectorizer.fit_transform(df['cleaned_text']).toarray()

Labels
y = df['label'].values

Display the TF-IDF features
print(X)
1.2 Preprocessing Numerical Data (Normalization)
For numerical data, normalization (scaling) is important, especially when features have different ranges. Common techniques are Min-Max Scaling and Standardization (Z-score normalization).

Example: Min-Max Normalization
Min-Max scaling transforms the data to a [0, 1] range:


from sklearn.preprocessing import MinMaxScaler

Example numerical dataset
data = {'age': [25, 30, 22, 35],
        'salary': [50000, 60000, 45000, 80000]}

df = pd.DataFrame(data)

Initialize MinMaxScaler
scaler = MinMaxScaler()

Apply MinMax scaling
df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)

Display scaled data
print(df_scaled)
Example: Standardization (Z-Score Normalization)
Standardization centers the data by subtracting the mean and dividing by the standard deviation:


from sklearn.preprocessing import StandardScaler

Initialize StandardScaler
scaler = StandardScaler()

Apply Standard scaling
df_standardized = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)

Display standardized data
print(df_standardized)
Step 2: Split the Dataset into

Train-Test Split (for both text and numerical data)
We use train_test_split() from scikit-learn to split
Split the data into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

Display the size of the splits
print(f"Training data size: {X_train.shape[0]}")
print(f"Testing data size: {X_test.shape[0]}")
For the text dataset, this will split the features (the numerical TF-IDF values) and the target labels into training and testing sets. Similarly, for numerical data, it will split the normalized or standardized features and labels.

Step 3: Putting It All Together
Here's a more complete example of how to clean, preprocess, and split both text and numerical data

import pandas as pd
import string
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import MinMaxScaler
import nltk


nltk.download('punkt')
nltk.download('stopwords')


data = {'text': ['I love programming in Python', 'Python is great for data science', 'I enjoy machine learning', 'Deep learning is fascinating'],
        'age': [25, 30, 22, 35],
        'salary': [50000, 60000, 45000, 80000],
        'label': [1, 1, 1, 0]}

df = pd.DataFrame(data)

 Step 1: Preprocess text data
def preprocess_text(text):
    text = text.lower()
    text = ''.join([char for char in text if char not in string.punctuation and not char.isdigit()])
    tokens = word_tokenize(text)
    stop_words = set(stopwords.words('english'))
    tokens = [word for word in tokens if word not in stop_words]
    return ' '.join(tokens)

df['cleaned_text'] = df['text'].apply(preprocess_text)

Step 2: Vectorize text data using TF-IDF
vectorizer = TfidfVectorizer(max_features=100)
X_text = vectorizer.fit_transform(df['cleaned_text']).toarray()

Step 3: Normalize numerical data (age, salary)
scaler = MinMaxScaler()
X_numerical = scaler.fit_transform(df[['age', 'salary']])

import numpy as np
X_combined = np.hstack([X_text, X_numerica

y = df['label'].values

X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)

print(f"Training data size: {X_train.shape[0]}")
print(f"Testing data size: {X_test.shape[0]}")

Step-4: Choose a Model:

 import tensorflow as tf

# Load a pre-trained model (MobileNetV2)
model = tf.keras.applications.MobileNetV2(weights='imagenet')

# Summarize the model
model.summary()
PyTorch:
To load a pre-trained model (e.g., ResNet18):


import torch
import torchvision.models as models

# Load a pre-trained model (ResNet18)
model = models.resnet18(pretrained=True)

# Set the model to evaluation mode
model.eval()

# Print the model architecture
print(model)
Hugging Face Transformers:
To load a pre-trained model for NLP (e.g., BERT):


from transformers import BertForSequenceClassification, BertTokenizer

# Load pre-trained BERT model and tokenizer
model = BertForSequenceClassification.from_pretrained('bert-base-uncased')
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

# Example text input
input_text = "Hello, how are you?"

# Tokenize and encode input
inputs = tokenizer(input_text, return_tensors='pt')

# Make predictions
outputs = model(**inputs)
2. Defining a Custom Model
TensorFlow / Keras:
Define a custom neural network using the Keras API:

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout

# Define a custom model
model = Sequential([
    Dense(64, activation='relu', input_shape=(32,)),
    Dropout(0.2),
    Dense(32, activation='relu'),
    Dense(10, activation='softmax')
])

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Summarize the model
model.summary()
PyTorch:
Define a custom neural network model:



import torch
import torch.nn as nn

class CustomModel(nn.Module):
    def __init__(self):
        super(CustomModel, self).__init__()
        self.fc1 = nn.Linear(32, 64)
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 10)
        self.relu = nn.ReLU()
        self.softmax = nn.Softmax(dim=1)

    def forward(self, x):
        x = self.relu(self.fc1(x))
        x = self.relu(self.fc2(x))
        x = self.softmax(self.fc3(x))
        return x

# Instantiate the custom model
model = CustomModel()

# Print the model architecture
print(model)
Hugging Face Transformers:
To define a custom model for NLP tasks (e.g., text classification), you can subclass a pre-trained model:


from transformers import BertForSequenceClassification

class CustomBertModel(BertForSequenceClassification):
    def __init__(self, config):
        super().__init__(config)

    def forward(self, input_ids, attention_mask=None):
        Add custom layers or behavior here if necessary
        return super().forward(input_ids, attention_mask)

Define custom model with a specific number of output classes
custom_model = CustomBertModel.from_pretrained('bert-base-uncased', num_labels=5)

step- 5

stimport tensorflow as tf
from tensorflow.keras.datasets import cifar10
from tensorflow.keras import layers, models

Step 1: Load and preprocess the CIFAR-10 dataset
(x_train, y_train), (x_test, y_test) = cifar10.load_data()

Normalize pixel values to be between 0 and 1
x_train, x_test = x_train / 255.0, x_test / 255.0

Step 2: Define a simple Convolutional Neural Network model
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax')
])

Step 3: Compile the model
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

Step 4: Train the model
model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))

Step 5: Evaluate the model
test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)
print(f"Test accuracy: {test_acc}")
2. Using PyTorch:
Example: Training a Model for Image Classification (CIFAR-10 dataset)
Steps:

Load and preprocess the dataset (e.g., CIFAR-10).
Define the model.
Set up loss function, optimizer, and training loop.
Train the model.


import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import torchvision
import torchvision.transforms as transforms

Step 1: Load and preprocess the CIFAR-10 dataset
transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
trainloader = DataLoader(trainset, batch_size=64, shuffle=True)

testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
testloader = DataLoader(testset, batch_size=64, shuffle=False)

Step 2: Define a simple CNN model
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
        self.fc1 = nn.Linear(64*8*8, 128)
        self.fc2 = nn.Linear(128, 10)


    def forward(self, x):
        x = torch.relu(self.conv1(x))
        x = torch.max_pool2d(x, 2)
        x = torch.relu(self.conv2(x))
        x = torch.max_pool2d(x, 2)
        x = x.view(-1, 64*8*8)
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x

Step 3: Define the loss function and optimizer
model = Net()
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

Step 4: Train the model
for epoch in range(10):
    running_loss = 0.0
    for inputs, labels in trainloader:
        optimizer.zero_grad()

        Forward pass
        outputs = model(inputs)
        loss = criterion(outputs, labels)

        Backward pass and optimize
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    print(f"Epoch {epoch+1}, Loss: {running_loss/len(trainloader)}")

Step 5: Evaluate the model
correct = 0
total = 0
with torch.no_grad():
    for inputs, labels in testloader:
        outputs = model(inputs)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print(f"Test Accuracy: {100 * correct / total}%")
3. Using Hugging Face Transformers (for NLP tasks):
Example: Training a BERT model for text classification
Steps:

Load and preprocess the dataset (e.g., IMDB dataset).
Load a pre-trained BERT model.
Fine-tune the model on your data.


from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments
from datasets import load_dataset

Step 1: Load and preprocess the IMDB dataset
dataset = load_dataset("imdb")
tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")

def tokenize_function(examples):
    return tokenizer(examples['text'], padding="max_length", truncation=True)

tokenized_datasets = dataset.map(tokenize_function, batched=True)

Step 2: Load the pre-trained BERT model for text classification
model = BertForSequenceClassification.from_pretrained("bert-base-uncased", num_labels=2)

Step 3: Define training arguments
training_args = TrainingArguments(
    output_dir="./results",
    evaluation_strategy="epoch",
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=3,
    logging_dir="./logs",
)

Step 4: Initialize the Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["test"],
)

Step 5: Train the model
trainer.train()

Step 6: Evaluate the model

step -6

import numpy as np
from sklearn.metrics import accuracy_score, f1_score

 Step 1: Make predictions on the test set
y_pred = model.predict(x_test)
y_pred_classes = np.argmax(y_pred, axis=1)

 Step 2: Calculate accuracy and F1-score
accuracy = accuracy_score(y_test, y_pred_classes)
f1 = f1_score(y_test, y_pred_classes, average='weighted')

 Step 3: Display the results
print(f"Test Accuracy: {accuracy * 100:.2f}%")
print(f"F1 Score (Weighted): {f1:.2f}")
2. Using PyTorch
Example: Predictions and Metrics for Image Classification (CIFAR-10)

import torch
from sklearn.metrics import accuracy_score, f1_score

Step 1: Make predictions on the test set
model.eval()
all_preds = []
all_labels = []

with torch.no_grad():
    for inputs, labels in testloader:
        outputs = model(inputs)
        _, preds = torch.max(outputs, 1)
        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

Step 2: Calculate accuracy and F1-score
accuracy = accuracy_score(all_labels, all_preds)
f1 = f1_score(all_labels, all_preds, average='weighted')

 Step 3: Display the results
print(f"Test Accuracy: {accuracy * 100:.2f}%")
print(f"F1 Score (Weighted): {f1:.2f}")
3. Using Hugging Face Transformers (for Text Classification)
Example: Predictions and Metrics for Text Classification (IMDB dataset)


from sklearn.metrics import accuracy_score, f1_score
import torch

Step 1: Make predictions on the test set
model.eval()
all_preds = []
all_labels = []

for batch in trainer.get_test_dataloader():
    inputs = batch["input_ids"].to(model.device)
    labels = batch["labels"].to(model.device)

    with torch.no_grad():
        outputs = model(inputs)
        logits = outputs.logits
        preds = torch.argmax(logits, dim=-1)

    all_preds.extend(preds.cpu().numpy())
    all_labels.extend(labels.cpu().numpy())

Step 2: Calculate accuracy and F1-score
accuracy = accuracy_score(all_labels, all_preds)
f1 = f1_score(all_labels, all_preds, average='weighted')

Step 3: Display the results
print(f"Test Accuracy: {accuracy * 100:.2f}%")
print(f"F1 Score (Weighted): {f1:.2f}")
Explanation of Metrics:
Accuracy: Measures the proportion of correct predictions (i.e., how many times the predicted class matches the true class).
F1-Score: The harmonic mean of precision and recall, which is useful when dealing with class imbalance. The weighted average is used in multi-class settings to take class imbalances into account.
Additional Metrics (Optional):
If you want to compute additional metrics like precision, recall, or confusion matrix, you can do so using sklearn.metrics:


from sklearn.metrics import precision_score, recall_score, confusion_matrix

Calculate precision and recall
precision = precision_score(all_labels, all_preds, average='weighted')
recall = recall_score(all_labels, all_preds, average='weighted')

 Confusion matrix
conf_matrix = confusion_matrix(all_labels, all_preds)

Display the results
print(f"Precision (Weighted): {precision:.2f}")
print(f"Recall (Weighted): {recall:.2f}")
print("Confusion Matrix:")
print(conf_matrix)
This process will allow you to evaluate the model's performance on the test set. Let me know if you need any further clarifications or adjustments!